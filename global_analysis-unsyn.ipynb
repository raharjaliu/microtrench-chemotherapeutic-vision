{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import copy\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm\n",
    "from sys import getsizeof\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import gamma\n",
    "\n",
    "import cv2\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiffcapture as tc\n",
    "\n",
    "from tifffile import imsave\n",
    "from matplotlib import pyplot as pt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from notebook.nbextensions import check_nbextension\n",
    "check_nbextension('codefolding', user=True)\n",
    "check_nbextension('codefolding/main.js', user=True)\n",
    "\n",
    "ext_require_path = 'codefolding/main'\n",
    "try:  # notebook >= 4.2.0\n",
    "    from notebook.nbextensions import enable_nbextension\n",
    "    enable_nbextension('notebook', ext_require_path)\n",
    "except ImportError:\n",
    "    from notebook.nbextensions import EnableNBExtensionApp\n",
    "    EnableNBExtensionApp().enable_nbextension(ext_require_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME_UNIT_FACTOR = 600\n",
    "PIXEL_INCH_RATIO = .647\n",
    "DIAMETER = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"\n",
    "    Remove a key from a  dictionary without destroying the reference\n",
    "    to removed object (which might be used by other processes)\n",
    "    \"\"\"\n",
    "    if key in d:\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_trees(links_tab, verbose=False, parse_velocity_displacement=False):\n",
    "    \"\"\"\n",
    "    Given 'links in tab statistics' from TrackMate.\n",
    "    Construct data structures representing trees ('tree') and\n",
    "    their branching ('branch') respectively.\n",
    "    \n",
    "    -   'tree' contains mapping of TREE_ID (which is the same as\n",
    "        the id of root's SPOT_ID) to its associated tree.\n",
    "        Each tree is in turn a map of TREE_BRANCH_ID\n",
    "        (which is the branch's first spot's SPOT_ID)\n",
    "        to its branch which is represented as list of SPOT_ID's.\n",
    "    -   'branch' encodes how the tree is structured. It contains\n",
    "        mapping of TREE_ID to the branching configuration.\n",
    "        The branching configuration is encoded as mapping of\n",
    "        BRANCH_ID to its two children's BRANCH_ID.\n",
    "    \"\"\"\n",
    "    \n",
    "    links_tab = links_tab.copy()\n",
    "    links_tab.index = links_tab.SPOT_TARGET_ID\n",
    "\n",
    "    tree = {}\n",
    "    branch = {}\n",
    "    if parse_velocity_displacement:\n",
    "        velocity = {}\n",
    "        displacement = {}\n",
    "        \n",
    "    for track in links_tab.TRACK_ID.unique():\n",
    "    \n",
    "        sub = links_tab[links_tab.TRACK_ID == track]\n",
    "\n",
    "        this_lines = {}\n",
    "        this_branches = {}\n",
    "        if parse_velocity_displacement:\n",
    "            this_velocities = {}\n",
    "            this_displacements = {}\n",
    "        stack = []\n",
    "    \n",
    "        groot = sub.iloc[0][3]\n",
    "        if verbose:\n",
    "            print(\"Parsing tree %s\" % groot)\n",
    "        stack.append(groot)\n",
    "    \n",
    "        while len(stack) > 0:\n",
    "        \n",
    "            root = stack.pop()\n",
    "            track = [root]\n",
    "            if parse_velocity_displacement:\n",
    "                # initial velocity and displacement is always 0\n",
    "                vel = [0]\n",
    "                disp = [0]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Parsing subtree %s\" % root)\n",
    "            nsub = sub[sub.SPOT_SOURCE_ID == root]\n",
    "        \n",
    "            while nsub.index.size > 0:\n",
    "                if nsub.index.size == 1:\n",
    "                    this = nsub.iloc[0][4]\n",
    "                    track.append(this)\n",
    "                    if parse_velocity_displacement:\n",
    "                        vel.append(sub.loc[this]['VELOCITY'])\n",
    "                        disp.append(sub.loc[this]['DISPLACEMENT'])\n",
    "                    nsub = sub[sub.SPOT_SOURCE_ID == this]\n",
    "                else:\n",
    "                    stack.append(nsub.iloc[0][4])\n",
    "                    stack.append(nsub.iloc[1][4])\n",
    "                    this_branches[root] = (nsub.iloc[0][4], nsub.iloc[1][4])\n",
    "                    if verbose:\n",
    "                        print(\"breaking\")\n",
    "                    break\n",
    "                \n",
    "            this_lines[root] = track\n",
    "            if parse_velocity_displacement:\n",
    "                this_velocities[root] = vel\n",
    "                this_displacements[root] = disp\n",
    "            if verbose:\n",
    "                print(\"adding branch %s\" % root)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"Finishing...\")\n",
    "        tree[groot] = this_lines\n",
    "        branch[groot] = this_branches\n",
    "        if parse_velocity_displacement:\n",
    "            velocity[groot] = this_velocities\n",
    "            displacement[groot] = this_displacements\n",
    "        \n",
    "    if parse_velocity_displacement:\n",
    "        return tree, branch, velocity, displacement\n",
    "    else:\n",
    "        return tree, branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_values(tree, spots_tab, colnames, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract varoius measurement values from spots statistics and save it\n",
    "    in format similar to parsed tree. The list of values to be extracted\n",
    "    from spots statistics is defined in 'colnames' \n",
    "    \n",
    "    The information will be stored in following format:\n",
    "    map(TYPE:(TREE_ID:TREE_BRANCH:list(VALUES))\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vals = {}\n",
    "\n",
    "    for tr in tree:\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"extracting values for %s\" % tr)\n",
    "    \n",
    "        for colname in colnames:\n",
    "        \n",
    "            val_tree = {}\n",
    "        \n",
    "            for br in tree[tr]:\n",
    "            \n",
    "                brkeys = tree[tr][br]\n",
    "                brvals = [sits[sits.ID == x][colname].values[0] for x in brkeys]\n",
    "            \n",
    "                val_tree[br] = brvals\n",
    "            \n",
    "            if colname not in vals:\n",
    "                vals[colname] = {}\n",
    "            \n",
    "            vals[colname][tr] = val_tree\n",
    "            \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_trees_by_time(tree, branch, tree_values, min_time=0, max_time=10):\n",
    "    \"\"\"\n",
    "    Filter out trees which measurement time start before or after\n",
    "    the time as defined in 'min_time' and 'max_time'.\n",
    "    \n",
    "    Measurement time is defined as the return value from TrackMate\n",
    "    encoded as 'POSITION_T'\n",
    "    \"\"\"\n",
    "    \n",
    "    tree_values_filtered = {}\n",
    "    tree = copy.deepcopy(tree)\n",
    "    branch = copy.deepcopy(branch)\n",
    "\n",
    "    for v in tree_values.keys():\n",
    "        tree_values_filtered[v] = {}\n",
    "\n",
    "    for key in tree_values['POSITION_T'].keys():\n",
    "    \n",
    "        if (tree_values['POSITION_T'][key][key][0] >= min_time) and (tree_values['POSITION_T'][key][key][0] <= max_time):\n",
    "            for k in tree_values_filtered.keys():\n",
    "                tree_values_filtered[k][key] = tree_values[k][key]\n",
    "        else:\n",
    "            tree = removekey(tree, key)\n",
    "            branch = removekey(branch, key)\n",
    "                \n",
    "    return  tree, branch, tree_values_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video(path, to_rgb=False):\n",
    "    \"\"\"\n",
    "    Read TIFF file containing multiple stacks (a video)\n",
    "    and return sequential array of frame encoded as\n",
    "    multidimensional array\n",
    "    \"\"\"\n",
    "    \n",
    "    tif = tc.opentiff(path)\n",
    "    \n",
    "    ## first image\n",
    "    _, first_img = tif.retrieve()\n",
    "    if to_rgb:\n",
    "        first_img = cv2.cvtColor(first_img,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    ## slices\n",
    "    pics = [first_img]\n",
    "\n",
    "    for slide in tif:\n",
    "        # convert grayscale to RGB\n",
    "        if to_rgb:\n",
    "            slide = cv2.cvtColor(slide, cv2.COLOR_GRAY2RGB)\n",
    "        pics.append(slide)\n",
    "    \n",
    "    return pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_brightness(tree_id, \n",
    "                       tree, \n",
    "                       tree_values, \n",
    "                       reference_vid_path, \n",
    "                       diameter=DIAMETER, \n",
    "                       caspase=True, \n",
    "                       normalize=True, \n",
    "                       synchronized=False):\n",
    "    \"\"\"\n",
    "    Given cell death signal video, extract brightness level for each position\n",
    "    of tracked cell trees, if such poisition coincides with the.\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics = get_video(reference_vid_path)\n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = []\n",
    "        for pic in pics:\n",
    "            base_brightness.append(cv2.sumElems(pic)[0] / float(pic.shape[0] * pic.shape[1]))\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)     \n",
    "            else:\n",
    "                if ((time[i] - 76200) >= 0) & ((time[i] - 76200) % 1800 == 0):\n",
    "                    pos = (time[i] - 76200) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    pic_bg = np.zeros(pic_base.shape, np.uint16)\n",
    "                    pic_bg = cv2.circle(pic_bg, \n",
    "                                       (int(x[i] / PIXEL_INCH_RATIO), int(y[i] / PIXEL_INCH_RATIO)),\n",
    "                                       int(diameter / PIXEL_INCH_RATIO),\n",
    "                                       (255, 255, 255),\n",
    "                                       -1)\n",
    "                    pic = cv2.bitwise_and(pic_base, pic_bg)\n",
    "                    if normalize:\n",
    "                        brightness.append(cv2.sumElems(pic)[0] / (base_brightness[pos] + .0001))\n",
    "                    else:\n",
    "                        brightness.append(cv2.sumElems(pic)[0])\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_brightness_template(tree_id,\n",
    "                                tree,\n",
    "                                tree_values,\n",
    "                                pics,\n",
    "                                diameter=DIAMETER,\n",
    "                                caspase=True,\n",
    "                                normalize=True,\n",
    "                                synchronized=False,\n",
    "                                pixel_inch_ratio=PIXEL_INCH_RATIO):\n",
    "    \"\"\"\n",
    "    Similar to extract_brightness(), except that it\n",
    "    takes video template form the user\n",
    "    \n",
    "    This function returns:\n",
    "    -   the brightness level of each spot in the tree, if such is measured.\n",
    "        The encoding follows that of the tree itself\n",
    "    -   cell death signal time-lapsed video of containing the cell belonging\n",
    "        to the 'tree_id'. Useful for debugging/sanity testing \n",
    "    \"\"\"\n",
    "    \n",
    "    pics_intersect = []\n",
    "\n",
    "    t_time = tree_values['POSITION_T'][tree_id] # tree_values\n",
    "    t_x = tree_values['POSITION_X'][tree_id]\n",
    "    t_y = tree_values['POSITION_Y'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "\n",
    "    t_brightness = {}\n",
    "    \n",
    "    if normalize:\n",
    "        base_brightness = [np.sum(pc.astype(np.int64)) / float(pc.shape[0] * pc.shape[1]) for pc in pics]\n",
    "\n",
    "    for br in t_tree:\n",
    "        brch = t_tree[br]\n",
    "        x = t_x[br]\n",
    "        y = t_y[br]\n",
    "        time = t_time[br]\n",
    "        brightness = []\n",
    "    \n",
    "        for i in range(len(brch)):\n",
    "            if synchronized or (not caspase):\n",
    "                if time[i] % 1800 == 0:\n",
    "                    pos = time[i] // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    \n",
    "                    gridy,gridx = np.ogrid[0:pic_base.shape[0], 0:pic_base.shape[1]]\n",
    "                    mask = (gridx - x[i])**2 + (gridy - y[i])**2 <= (diameter / pixel_inch_ratio)**2\n",
    "                    pic = pic_base[mask]\n",
    "        \n",
    "                    if normalize:\n",
    "                        val = np.sum(pic, dtype=np.int64) / (base_brightness[pos] + .0001)\n",
    "                        brightness.append(val)\n",
    "                    else:\n",
    "                        val = np.sum(pic, dtype=np.int64)\n",
    "                        brightness.append(val)\n",
    "    \n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            else:\n",
    "                if ((time[i] - 77400) >= 0) & ((time[i] - 77400) % 1800 == 0):\n",
    "                    pos = (time[i] - 77400) // 1800\n",
    "                    pic_base = pics[pos]\n",
    "                    \n",
    "                    cx = x[i] / pixel_inch_ratio\n",
    "                    cy = y[i] / pixel_inch_ratio\n",
    "                    \n",
    "                    \n",
    "                    gridy,gridx = np.ogrid[0:pic_base.shape[0], 0:pic_base.shape[1]]\n",
    "                    mask = (gridx - cx)**2 + (gridy - cy)**2 <= (diameter / pixel_inch_ratio)**2\n",
    "                    pic = pic_base[mask]\n",
    "\n",
    "                    if normalize:\n",
    "                        val = np.sum(pic, dtype=np.int64) / (base_brightness[pos] + .0001)\n",
    "                        brightness.append(val)\n",
    "                    else:\n",
    "                        val = np.sum(pic, dtype=np.int64)\n",
    "                        brightness.append(val)\n",
    "                    pics_intersect.append(pic)\n",
    "                else:\n",
    "                    brightness.append(np.nan)\n",
    "            \n",
    "        t_brightness[br] = brightness\n",
    "    return t_brightness, np.array(pics_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_tree_to_contours(tree_values, contours, pixel_inch_ratio=PIXEL_INCH_RATIO):\n",
    "    \"\"\"\n",
    "    Given tree values and recognized contours, compute:\n",
    "    \n",
    "    -   'assocs': table listing recognized slit and the TREE_ID\n",
    "        of singly-placed cell tree located in the slit\n",
    "    -   'occupancy': list containing the number of cell trees\n",
    "        located in a slit. NOTE: the list is not associated with\n",
    "        ordering encoded in 'assocs'\n",
    "    \"\"\"\n",
    "\n",
    "    occuppancy = {x:0 for x in range(len(contours))}\n",
    "    cell_trees = []\n",
    "    slits = []\n",
    "\n",
    "    for tr in tree_values['POSITION_X'].keys():\n",
    "    \n",
    "        cell_trees.append(tr)\n",
    "\n",
    "        x = tree_values['POSITION_X'][tr][tr][0] / pixel_inch_ratio\n",
    "        y = tree_values['POSITION_Y'][tr][tr][0] / pixel_inch_ratio\n",
    "    \n",
    "        counter = 0\n",
    "        match = 0\n",
    "        matchloc = None\n",
    "    \n",
    "        for ct in cts:\n",
    "        \n",
    "            if cv2.pointPolygonTest(ct, (x, y), False) > 0:\n",
    "                occuppancy[counter] += 1\n",
    "                matchloc = counter\n",
    "                match += 1\n",
    "            counter +=  1\n",
    "        \n",
    "        if match == 0:\n",
    "            slits.append(None)\n",
    "        elif match == 1:\n",
    "            slits.append(matchloc)\n",
    "        else:\n",
    "            print(\"Tree %s got too many matches\" % tr)\n",
    "        \n",
    "    assocs = pd.DataFrame({'CELL_LINE': cell_trees, 'SLIT_ID': slits})\n",
    "    occuppancy = np.array(list(occuppancy.values()))\n",
    "    \n",
    "    return assocs, occuppancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contour(contour_mask_path, min_size=7000, max_size=10000):\n",
    "    \"\"\"\n",
    "    Give contour mask picture (created by adjusting contrast/brightness\n",
    "    followed by RATS and \"fill holes\" command) detect contours of\n",
    "    slits annd return:\n",
    "    - the list of filtered contours\n",
    "    - the size list of filtered contours\n",
    "    - the size of all detected contours (for testing purpose)\n",
    "    \"\"\"\n",
    "    \n",
    "    ## collect contours and wrap into a function\n",
    "\n",
    "    im = cv2.imread(contour_mask_path)\n",
    "    gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    im2, contours, hierarchy  = cv2.findContours(gray,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    all_cts_area = np.array([cv2.contourArea(x) for x  in contours])\n",
    "\n",
    "    filtered_cts = []\n",
    "    filtered_cts_area = []\n",
    "\n",
    "    for ct in contours:\n",
    "        ct_area = cv2.contourArea(ct)\n",
    "        if (ct_area <= max_size) and (ct_area >= min_size):\n",
    "            filtered_cts.append(ct)\n",
    "            filtered_cts_area.append(ct_area)\n",
    "            \n",
    "    return filtered_cts, filtered_cts_area, all_cts_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trees_by_placement(tree_assoc, placement=1):\n",
    "    \"\"\"\n",
    "    Get all cell trees that have the same placement as described in argument.\n",
    "    A cell tree is of placement n if it is located in a slit with (n - 1)\n",
    "    other cell trees. 'placement' is by definition larger than 0\n",
    "    \"\"\"\n",
    "    if placement < 1:\n",
    "        print(\"'placement' has to be at least 1\")\n",
    "        return []\n",
    "    else:\n",
    "        trees = []\n",
    "        for slit in tree_assoc.SLIT_ID.unique():\n",
    "            if tree_assoc[tree_assoc.SLIT_ID == slit].index.size == placement:\n",
    "                trees.append(tree_assoc[tree_assoc.SLIT_ID == slit]['CELL_LINE'].values[0])\n",
    "    \n",
    "        return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_first_division_time(tree_id, tree, branch, tree_measurements, mode=['avg', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Compute the first division time of a tree. The first division time\n",
    "    could be computed with following mode:\n",
    "    \n",
    "    -   'avg': averaging time difference between the last measurement\n",
    "        time of main branch and first measurement time of each \n",
    "        child branches\n",
    "    -   'min': taking the minimum of both values\n",
    "    -   'max': taking the maximum of both values\n",
    "    \"\"\"    \n",
    "    \n",
    "    t_time = tree_measurements['POSITION_T'][tree_id]\n",
    "    t_tree = tree[tree_id]\n",
    "    t_branch = branch[tree_id]\n",
    "    \n",
    "    div_end_main = t_time[tree_id][-1]\n",
    "    div_start_1 = t_time[t_branch[tree_id][0]][0]\n",
    "    div_start_2 = t_time[t_branch[tree_id][1]][0]\n",
    "    \n",
    "    if mode == 'avg':\n",
    "        return div_end_main + float(div_start_1 + div_start_2 - 2 * div_end_main) / 4\n",
    "    elif mode == 'min':\n",
    "        return div_end_main + min((div_start_2 - div_end_main) / 2, (div_start_2 - div_end_main) / 2)\n",
    "    elif mode == 'max':\n",
    "        return div_end_main + max((div_start_2 - div_end_main) / 2, (div_start_2 - div_end_main) / 2)\n",
    "    elif mode == ['avg', 'min', 'max']:\n",
    "        # default mode, compute avg\n",
    "        return div_end_main + float(div_start_1 + div_start_2 - 2 * div_end_main) / 4\n",
    "    else:\n",
    "        raise(\"Wrong mode. Mode has to be either 'avg', 'max' or 'min\")\n",
    "        \n",
    "\n",
    "def compute_first_division_time_list(tree_ids, tree, branch, tree_measurements, mode=['avg', 'min', 'max']):\n",
    "    \"\"\"\n",
    "    Wrapper function of compute_first_division_time().\n",
    "    This function takes list of TREE_IDs and compute \n",
    "    the first division time for each tree.\n",
    "    \"\"\"\n",
    "\n",
    "    div_times = []\n",
    "\n",
    "    for t in tree_ids:\n",
    "        div_times.append(compute_first_division_time(t, tree, branch, tree_measurements, mode=mode))\n",
    "    \n",
    "#         print(\"t1, t2, t3: %d, %d, %d\" % (div_end_main, div_start_1, div_start_2))\n",
    "#         print(\"t_div: %f\" % div_time)\n",
    "    \n",
    "    return div_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_invalid_trees(singly_placed_tree, tree, branch, tree_values):\n",
    "    \"\"\"\n",
    "    Iteratively filter out invalid trees.\n",
    "    \n",
    "    Strategy:\n",
    "\n",
    "    I.  For one division analysis\n",
    "        1. Find singly placed trees:\n",
    "        2. Do Cell Death Signal Filtering\n",
    "        3. Find tree with one division\n",
    "        4. Find tree with T(div) < t(treatment)\n",
    "        5. Find tree with T(death) > t(treatment)\n",
    "        \n",
    "    II. in the new implementation the cells with no division are also valid\n",
    "    \n",
    "    Collected statistics:\n",
    "    1. # singly-placed slits\n",
    "    2. # tree with zero div\n",
    "    3. # tree with one div\n",
    "    4. # tree with T(div) < t(treatment)\n",
    "    5. # tree with T(death) > t(treatment)\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate number of divs for each tree\n",
    "    singly_placed_tree_div = []\n",
    "    for t in singly_placed_tree:\n",
    "        ### return: tree-division\n",
    "        singly_placed_tree_div.append(len(tree_values['POSITION_T'][t].keys()))\n",
    "\n",
    "    ## filter out trees having other than one division\n",
    "    \n",
    "    # trees with one division event\n",
    "    ### return: no div tree\n",
    "    invalid_tree_nodiv = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) == 1])\n",
    "    ### non-return: no div tree with last timestamp < treatment\n",
    "    invalid_tree_nodiv_last_before_trtmt = list(filter(lambda x: tree_values['POSITION_T'][x][x][-1] < 126 * TIME_UNIT_FACTOR, \n",
    "                                                       invalid_tree_nodiv))\n",
    "    ### return: more one div tree\n",
    "    invalid_tree_morethan1div = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) > 3])\n",
    "    ### return: one div tree\n",
    "    tree_one_div = list(np.array(singly_placed_tree)[np.array(singly_placed_tree_div) == 3])\n",
    "\n",
    "    print(\"    # of singly-placed trees with 0 div: %d\" % len(invalid_tree_nodiv))\n",
    "    print(\"    # of singly-placed trees with 0 div with last timestamp < t(treatment): %d\" % len(invalid_tree_nodiv_last_before_trtmt))\n",
    "    print(\"    # of singly-placed trees with 1 div: %d\" % len(tree_one_div))\n",
    "    print(\"    # of singly-placed trees with >1 divs: %d\" % len(invalid_tree_morethan1div))\n",
    "\n",
    "    ## compute div times\n",
    "    \n",
    "    ### return: division times of one div tree\n",
    "    tree_one_div_div_times = compute_first_division_time_list(tree_one_div, tree, branch, tree_values, mode='avg')\n",
    "\n",
    "    ## filter out trees with division after treatment\n",
    "\n",
    "    valid = np.array(tree_one_div_div_times) < (126 * TIME_UNIT_FACTOR)\n",
    "    \n",
    "    invalid_tree_divaftertreatment = list(np.array(tree_one_div)[~valid])\n",
    "    ### return: div before treatment tree\n",
    "    tree_divbfrtreatment = list(np.array(tree_one_div)[valid])\n",
    "    ### return: division times of div before treatment tree\n",
    "    tree_divbfrtreatment_div_times = list(np.array(tree_one_div_div_times)[valid])\n",
    "\n",
    "    print(\"    # trees with division time before treatment: %d\" % len(tree_divbfrtreatment))\n",
    "    \n",
    "    ## filter out trees with child's death before treatment\n",
    "\n",
    "    # compute the death time of both child branches\n",
    "    death_times_1 = []\n",
    "    death_times_2 = []\n",
    "\n",
    "    for t in tree_divbfrtreatment:\n",
    "        t_time = tree_values['POSITION_T'][t]\n",
    "        t_tree = tree[t]\n",
    "        t_branch = branch[t]\n",
    "    \n",
    "        last_time_1 = t_time[t_branch[t][0]][-1]\n",
    "        last_time_2 = t_time[t_branch[t][1]][-1]\n",
    "    \n",
    "        death_times_1.append(last_time_1)\n",
    "        death_times_2.append(last_time_2)\n",
    "\n",
    "    valid1 = np.array(death_times_1) > (126 * TIME_UNIT_FACTOR)\n",
    "    valid2 = np.array(death_times_2) > (126 * TIME_UNIT_FACTOR)\n",
    "    valid = valid1 & valid2\n",
    "    \n",
    "    tree_divbfrtreatment_last_time_1 = death_times_1\n",
    "    tree_divbfrtreatment_last_time_2 = death_times_2\n",
    "\n",
    "    invalid_tree_deathbeforetreatment = list(np.array(tree_divbfrtreatment)[~valid])\n",
    "    ## return: death after treatment tree\n",
    "    tree_deathaftertreatment = list(np.array(tree_divbfrtreatment)[valid])\n",
    "    ## return: death time of 1st child\n",
    "    last_time_1 = list(np.array(death_times_1)[valid])\n",
    "    ## return: death time of 2nd child\n",
    "    last_time_2 = list(np.array(death_times_2)[valid])\n",
    "    ## return:  division times of death after treatment tree\n",
    "    tree_deathaftertreatment_div_times = list(np.array(tree_divbfrtreatment_div_times)[valid])\n",
    "    print(\"    # trees with both branches' last measurement time after treatment: %d\" % len(tree_deathaftertreatment))\n",
    "    \n",
    "    return singly_placed_tree_div, \\\n",
    "            invalid_tree_nodiv, \\\n",
    "            invalid_tree_morethan1div, \\\n",
    "            tree_one_div, \\\n",
    "            tree_one_div_div_times, \\\n",
    "            tree_divbfrtreatment, \\\n",
    "            tree_divbfrtreatment_div_times, \\\n",
    "            tree_divbfrtreatment_last_time_1, \\\n",
    "            tree_divbfrtreatment_last_time_2, \\\n",
    "            tree_deathaftertreatment, \\\n",
    "            tree_deathaftertreatment_div_times, \\\n",
    "            last_time_1, \\\n",
    "            last_time_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stringify_position(position):\n",
    "    \n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "        \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTREE_ID:\\n    \"TREE\"\\n    \"BRANCH\"\\n    \"POSITION_T\"\\n    \"POSITION_X\"\\n    \"POSITION_Y\"\\n    \"CASPASE\"\\n    \"CASPASE_NORM\"\\n    \"CASPASE_SUB\"\\n    \"CASPASE_SUB_NORM\"\\n    \"PI\"\\n    \"PI_NORM\"\\n    \"PI_SUB\"\\n    \"PI_SUB_NORM\"\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TREE_ID:\n",
    "    \"TREE\"\n",
    "    \"BRANCH\"\n",
    "    \"POSITION_T\"\n",
    "    \"POSITION_X\"\n",
    "    \"POSITION_Y\"\n",
    "    \"CASPASE\"\n",
    "    \"CASPASE_NORM\"\n",
    "    \"CASPASE_SUB\"\n",
    "    \"CASPASE_SUB_NORM\"\n",
    "    \"PI\"\n",
    "    \"PI_NORM\"\n",
    "    \"PI_SUB\"\n",
    "    \"PI_SUB_NORM\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Read filtered data\n",
    "## I.1 Read filtered BF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"D:\\\\MA\\\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dauno_positions = set([stringify_position(x) for x in [32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_f = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "done_f = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions_f = list(set(list(range(64))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing position 01...\n",
      "  Reading files\n",
      "  Reading files done. Time elapsed: 0.272271\n",
      "  Parsing trees and values\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filter cells according to category:\n",
    "- 5 -- cells with one division dividing before treatment\n",
    "- 9 -- cells with one division dividing before treatment with both children dividing after treatment\n",
    "\"\"\"\n",
    "cell_category = 5\n",
    "## CONSIDERS THE CELLS WITH ONE DIVISION BEFORE TREATMENT\n",
    "\n",
    "contours = {}\n",
    "diameter = 15\n",
    "\n",
    "for position in positions_f:\n",
    "    \n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "    \n",
    "    if position not in done_f:\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"Processing position %s...\\n  Reading files\" % pos)\n",
    "\n",
    "        track_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/out-focus/merged/out/tracked/\" % pos)\n",
    "        caspase_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1.tif\" % (pos, pos))\n",
    "        caspase_sub_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1_sub.tif\" % (pos, pos))\n",
    "        pi_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged.tif\" % pos)\n",
    "        pi_sub_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged_sub_adjust.tif\" % pos)\n",
    "\n",
    "        ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "        sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "        print(\"  Reading files done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## parsing tree\n",
    "        t = time.time()\n",
    "        print(\"  Parsing trees and values\")\n",
    "        tree, branch, velocity, displacement = parse_trees(ba, parse_velocity_displacement=True)\n",
    "        svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])\n",
    "        print(\"  Parsing done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## filter tree\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"  Filtering tree\")\n",
    "        tree, branch, svals = filter_trees_by_time(tree, branch, svals)\n",
    "        print(\"  Filtering done. Time elapsed: %f\" % (time.time() - t))\n",
    "        \n",
    "        ## extract cell association\n",
    "        t = time.time()\n",
    "        print(\"  Getting contour\")\n",
    "        \n",
    "        path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/in-focus/before\" % pos)\n",
    "        impath = \"bf_in-focusxy%sc1c1-mask.tif\" % pos\n",
    "        \n",
    "        cts, _, _ = get_contour(os.path.join(path, impath))\n",
    "        assocs, _ = assign_tree_to_contours(svals, cts)\n",
    "        \n",
    "        ## save contours for later use (PI signaling)\n",
    "        contours[pos] = cts\n",
    "        \n",
    "        counts = assocs[~assocs.SLIT_ID.isnull()].groupby(\"SLIT_ID\").count().reset_index()\n",
    "        print(\"    # number of detected slits: %d\" % len(cts))\n",
    "        print(\"    # number of occupied slits: %d\" % counts.index.size)\n",
    "        print(\"    # number of slits with doubly-placed trees: %d\" % counts[counts.CELL_LINE == 2].size)\n",
    "        print(\"    # number of slits with triply-placed trees: %d\" % counts[counts.CELL_LINE == 3].size)\n",
    "        print(\"    # number of slits with quadruply-placed trees: %d\" % counts[counts.CELL_LINE == 4].size)\n",
    "        print(\"    # number of trees: %d\" % assocs[~assocs.SLIT_ID.isnull()].size)\n",
    "        ## keep only trees fulfilling the second strictest critera (division before treatment)\n",
    "        cell_trees = get_trees_by_placement(assocs, placement=1)\n",
    "        cell_trees = filter_invalid_trees(cell_trees, tree, branch, svals)[5]\n",
    "\n",
    "        print(\"  Contour recognition done. Time elapsed: %f\" % (time.time() - t))\n",
    "        ## extract cas + pi value\n",
    "\n",
    "        print(\"  Extarcting caspase and pi measurement values\")\n",
    "        t = time.time()\n",
    "        caspases = {}\n",
    "        caspases_norm = {}\n",
    "        caspases_sub = {}\n",
    "        caspases_sub_norm = {}\n",
    "        pis = {}\n",
    "        pis_norm = {}\n",
    "        pis_sub = {}\n",
    "        pis_sub_norm = {}\n",
    "    \n",
    "        pics_casp = get_video(caspase_path)\n",
    "        pics_casp_sub = get_video(caspase_sub_path)\n",
    "        pics_pi = get_video(pi_path)\n",
    "        pics_pi_sub = get_video(pi_sub_path)\n",
    "    \n",
    "        for k in cell_trees:\n",
    "\n",
    "            cs, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=False)\n",
    "            caspases[k] = cs\n",
    "    \n",
    "            csnorm, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=True)\n",
    "            caspases_norm[k] = csnorm\n",
    "    \n",
    "            cssub, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=False)\n",
    "            caspases_sub[k] = cssub\n",
    "    \n",
    "            cssubnorm, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=True)\n",
    "            caspases_sub_norm[k] = cssubnorm\n",
    "    \n",
    "        print(\"  Extracting caspase done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        t = time.time()\n",
    "        for k in cell_trees:\n",
    "            \n",
    "            pi, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=False)\n",
    "            pis[k] = pi\n",
    "        \n",
    "            pinorm, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=True)\n",
    "            pis_norm[k] = pinorm\n",
    "        \n",
    "            pisub, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=False)\n",
    "            pis_sub[k] = pisub\n",
    "        \n",
    "            pisubnorm, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=True)\n",
    "            pis_sub_norm[k] = pisubnorm\n",
    "    \n",
    "        print(\"  Extracting pi done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        print(\"  Wrapping values\")\n",
    "        t = time.time()\n",
    "        \n",
    "        pos_dat = {}\n",
    "        pos_dat_trees = {}\n",
    "        \n",
    "        for tr in cell_trees:\n",
    "            t_tree = {\n",
    "                \"TREE\": tree[tr],\n",
    "                \"BRANCH\": branch[tr],\n",
    "                \"POSITION_T\": svals[\"POSITION_T\"][tr],\n",
    "                \"POSITION_X\": svals[\"POSITION_X\"][tr],\n",
    "                \"POSITION_Y\": svals[\"POSITION_Y\"][tr],\n",
    "                \"CASPASE\": caspases[tr],\n",
    "                \"CASPASE_NORM\": caspases_norm[tr],\n",
    "                \"CASPASE_SUB\": caspases_sub[tr],\n",
    "                \"CASPASE_SUB_NORM\": caspases_sub_norm[tr],\n",
    "                \"PI\": pis[tr],\n",
    "                \"PI_NORM\": pis_norm[tr],\n",
    "                \"PI_SUB\": pis_sub[tr],\n",
    "                \"PI_SUB_NORM\": pis_sub_norm[tr],\n",
    "                \"VELOCITY\": velocity[tr],\n",
    "                \"DISPLACEMENT\": displacement[tr]\n",
    "            }\n",
    "            pos_dat_trees[tr] = t_tree\n",
    "    \n",
    "        pos_dat[\"TREES\"] = pos_dat_trees\n",
    "        pos_dat[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat_f[pos] = pos_dat\n",
    "        done_f.append(position)\n",
    "        \n",
    "        for tree_id in cell_trees:    \n",
    "            dat_f[pos][\"TREES\"][tree_id][\"SLIT_ID\"] = int(assocs[assocs.CELL_LINE == tree_id][\"SLIT_ID\"].values[0])\n",
    "\n",
    "        print(\"  Extraction done. Time elapsed: %f\" % (time.time() - t))\n",
    "    else:\n",
    "        print(\"  Position %s already extracted\" % pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dump pickle\n",
    "if cell_category == 5:\n",
    "    pickle.dump(dat_f, open(\"./unsyn_filtered_data_divided_before_treatment.p\", \"wb\"))\n",
    "else:    \n",
    "    pickle.dump(dat_f, open(\"./unsyn_filtered_data_divided_before_treatment_deaths_after_treatment.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(contours, open(\"./unsyn_contours.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_f = pickle.load(open(\"./unsyn_filtered_data_divided_before_treatment.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Create filtered data which only includes trees which children were last tracked ONLY after treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filtered data with kids tracked after treatment\n",
    "dat_fat = copy.deepcopy(dat_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in dat_fat:\n",
    "    to_delete = []\n",
    "    for tr in dat_fat[pos]['TREES']:\n",
    "        br1 = dat_fat[pos]['TREES'][tr]['BRANCH'][tr][0]\n",
    "        br2 = dat_fat[pos]['TREES'][tr]['BRANCH'][tr][1]\n",
    "        t1 = dat_fat[pos]['TREES'][tr]['POSITION_T'][br1][-1]\n",
    "        t2 = dat_fat[pos]['TREES'][tr]['POSITION_T'][br2][-1]\n",
    "\n",
    "        if (21 * 3600 > t1) or (21 * 3600 > t2):\n",
    "            to_delete.append(tr)\n",
    "    \n",
    "    for tr in to_delete:\n",
    "        del dat_fat[pos]['TREES'][tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_fat, open(\"./unsyn_filtered_data_divided_before_treatment_deaths_after_treatment.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3 Read PI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_ds = {}\n",
    "done_ds = []\n",
    "positions_ds = list(set(list(range(64))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for position in positions_ds:\n",
    "\n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "    \n",
    "    if position not in done_ds:\n",
    "        \n",
    "        t = time.time()\n",
    "        print(\"Processing position %s...\\n  Reading files\" % pos)\n",
    "\n",
    "        track_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/out_sub_adjust/\" % pos)\n",
    "        caspase_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1.tif\" % (pos, pos))\n",
    "        caspase_sub_path = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1_sub.tif\" % (pos, pos))\n",
    "        pi_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged.tif\" % pos)\n",
    "        pi_sub_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged_sub_adjust.tif\" % pos)\n",
    "\n",
    "        ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "        sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "        print(\"  Reading files done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## parsing tree\n",
    "        t = time.time()\n",
    "        print(\"  Parsing trees and values\")\n",
    "        tree, branch, velocity, displacement = parse_trees(ba, parse_velocity_displacement=True)\n",
    "        svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])\n",
    "        print(\"  Parsing done. Time elapsed: %f\" % (time.time() - t))\n",
    "        \n",
    "        ## extract cell association\n",
    "        t = time.time()\n",
    "        print(\"  Getting contour\")\n",
    "        \n",
    "        path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/in-focus/before\" % pos)\n",
    "        impath = \"bf_in-focusxy%sc1c1-mask.tif\" % pos\n",
    "        \n",
    "#         cts = contours[pos]\n",
    "        cts, _, _ = get_contour(os.path.join(path, impath))\n",
    "        assocs, _ = assign_tree_to_contours(svals, cts, pixel_inch_ratio=1)\n",
    "    \n",
    "        ## filter tracks outside slit out\n",
    "        cell_trees = assocs[~assocs.SLIT_ID.isnull()].CELL_LINE\n",
    "    \n",
    "        print(\"  Contour recognition done. Time elapsed: %f\" % (time.time() - t))\n",
    "        ## extract cas + pi value\n",
    "\n",
    "        print(\"  Extarcting caspase and pi measurement values\")\n",
    "        t = time.time()\n",
    "        caspases = {}\n",
    "        caspases_norm = {}\n",
    "        caspases_sub = {}\n",
    "        caspases_sub_norm = {}\n",
    "        pis = {}\n",
    "        pis_norm = {}\n",
    "        pis_sub = {}\n",
    "        pis_sub_norm = {}\n",
    "    \n",
    "        pics_casp = get_video(caspase_path)\n",
    "        pics_casp_sub = get_video(caspase_sub_path)\n",
    "        pics_pi = get_video(pi_path)\n",
    "        pics_pi_sub = get_video(pi_sub_path)\n",
    "    \n",
    "        for k in cell_trees:\n",
    "\n",
    "            cs, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=False, pixel_inch_ratio=1.)\n",
    "            caspases[k] = cs\n",
    "    \n",
    "            csnorm, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=True, pixel_inch_ratio=1.)\n",
    "            caspases_norm[k] = csnorm\n",
    "    \n",
    "            cssub, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=False, pixel_inch_ratio=1.)\n",
    "            caspases_sub[k] = cssub\n",
    "    \n",
    "            cssubnorm, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=True, pixel_inch_ratio=1.)\n",
    "            caspases_sub_norm[k] = cssubnorm\n",
    "    \n",
    "        print(\"  Extracting caspase done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        t = time.time()\n",
    "        for k in cell_trees:\n",
    "            \n",
    "            pi, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=False, pixel_inch_ratio=1.)\n",
    "            pis[k] = pi\n",
    "        \n",
    "            pinorm, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=True, pixel_inch_ratio=1.)\n",
    "            pis_norm[k] = pinorm\n",
    "        \n",
    "            pisub, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=False, pixel_inch_ratio=1.)\n",
    "            pis_sub[k] = pisub\n",
    "        \n",
    "            pisubnorm, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=True, pixel_inch_ratio=1.)\n",
    "            pis_sub_norm[k] = pisubnorm\n",
    "    \n",
    "        print(\"  Extracting pi done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        print(\"  Wrapping values\")\n",
    "        t = time.time()\n",
    "        \n",
    "        pos_dat = {}\n",
    "        pos_dat_trees = {}\n",
    "        \n",
    "        for tr in cell_trees:\n",
    "            t_tree = {\n",
    "                \"TREE\": tree[tr],\n",
    "                \"BRANCH\": branch[tr],\n",
    "                \"POSITION_T\": svals[\"POSITION_T\"][tr],\n",
    "                \"POSITION_X\": svals[\"POSITION_X\"][tr],\n",
    "                \"POSITION_Y\": svals[\"POSITION_Y\"][tr],\n",
    "                \"CASPASE\": caspases[tr],\n",
    "                \"CASPASE_NORM\": caspases_norm[tr],\n",
    "                \"CASPASE_SUB\": caspases_sub[tr],\n",
    "                \"CASPASE_SUB_NORM\": caspases_sub_norm[tr],\n",
    "                \"PI\": pis[tr],\n",
    "                \"PI_NORM\": pis_norm[tr],\n",
    "                \"PI_SUB\": pis_sub[tr],\n",
    "                \"PI_SUB_NORM\": pis_sub_norm[tr],\n",
    "                \"VELOCITY\": velocity[tr],\n",
    "                \"DISPLACEMENT\": displacement[tr]\n",
    "            }\n",
    "            pos_dat_trees[tr] = t_tree\n",
    "    \n",
    "        pos_dat[\"TREES\"] = pos_dat_trees\n",
    "        pos_dat[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat[\"PIXEL_TO_INCH\"] = 1\n",
    "        dat_ds[pos] = pos_dat\n",
    "        done_ds.append(position)\n",
    "        \n",
    "        for tree_id in cell_trees:    \n",
    "            dat_ds[pos][\"TREES\"][tree_id][\"SLIT_ID\"] = int(assocs[assocs.CELL_LINE == tree_id][\"SLIT_ID\"].values[0])\n",
    "\n",
    "        print(\"  Extraction done. Time elapsed: %f\" % (time.time() - t))\n",
    "    else:\n",
    "        print(\"  Position %s already extracted\" % pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dump pickle\n",
    "pickle.dump(dat_ds, open(\"./unsyn_filtered_data_pi_sub.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load pickle\n",
    "dat_ds = pickle.load(open(\"./unsyn_filtered_data_pi_sub.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4 Read cells having two generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_tg = {}\n",
    "done_tg = []\n",
    "positions_tg = list(set(list(range(64))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter cells according to category:\n",
    "- 5 -- cells with one division dividing before treatment\n",
    "- 9 -- cells with one division dividing before treatment with both children dividing after treatment\n",
    "\"\"\"\n",
    "cell_category = 5\n",
    "## CONSIDERS THE CELLS WITH ONE DIVISION BEFORE TREATMENT\n",
    "\n",
    "contours = {}\n",
    "diameter = 15\n",
    "\n",
    "for position in positions_tg:\n",
    "    \n",
    "    if position < 10:\n",
    "        pos = \"0%d\" % position\n",
    "    else:\n",
    "        pos = str(position)\n",
    "    \n",
    "    if position not in done_tg:\n",
    "\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"Processing position %s...\\n  Reading files\" % pos)\n",
    "\n",
    "        track_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/out-focus/merged/out/tracked/\" % pos)\n",
    "        caspase_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1.tif\" % (pos, pos))\n",
    "        caspase_sub_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/caspase/caspasexy%sc1_sub.tif\" % (pos, pos))\n",
    "        pi_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged.tif\" % pos)\n",
    "        pi_sub_path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/pi/merged/merged_sub_adjust.tif\" % pos)\n",
    "\n",
    "        ba = pd.read_csv(os.path.join(track_path, 'Links in tracks statistics.csv'))\n",
    "        sits = pd.read_csv(os.path.join(track_path, 'Spots in tracks statistics.csv'))\n",
    "        print(\"  Reading files done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## parsing tree\n",
    "        t = time.time()\n",
    "        print(\"  Parsing trees and values\")\n",
    "        tree, branch, velocity, displacement = parse_trees(ba, parse_velocity_displacement=True)\n",
    "        svals = extract_values(tree, sits, ['POSITION_T', 'POSITION_X', 'POSITION_Y', 'TOTAL_INTENSITY', 'QUALITY'])\n",
    "        print(\"  Parsing done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        ## filter tree\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"  Filtering tree\")\n",
    "        tree, branch, svals = filter_trees_by_time(tree, branch, svals)\n",
    "        print(\"  Filtering done. Time elapsed: %f\" % (time.time() - t))\n",
    "        \n",
    "        ## extract cell association\n",
    "        t = time.time()\n",
    "        print(\"  Getting contour\")\n",
    "        \n",
    "        path = = os.path.join(PATH_TO_DATA, \"eli-new-unsync-bf-%s/in-focus/before\" % pos)\n",
    "        impath = \"bf_in-focusxy%sc1c1-mask.tif\" % pos\n",
    "        \n",
    "        cts, _, _ = get_contour(os.path.join(path, impath))\n",
    "        assocs, _ = assign_tree_to_contours(svals, cts)\n",
    "        \n",
    "        ## save contours for later use (PI signaling)\n",
    "        contours[pos] = cts\n",
    "        \n",
    "        counts = assocs[~assocs.SLIT_ID.isnull()].groupby(\"SLIT_ID\").count().reset_index()\n",
    "        print(\"    # number of detected slits: %d\" % len(cts))\n",
    "        print(\"    # number of occupied slits: %d\" % counts.index.size)\n",
    "        print(\"    # number of slits with doubly-placed trees: %d\" % counts[counts.CELL_LINE == 2].size)\n",
    "        print(\"    # number of slits with triply-placed trees: %d\" % counts[counts.CELL_LINE == 3].size)\n",
    "        print(\"    # number of slits with quadruply-placed trees: %d\" % counts[counts.CELL_LINE == 4].size)\n",
    "        print(\"    # number of trees: %d\" % assocs[~assocs.SLIT_ID.isnull()].size)\n",
    "        \n",
    "        ## keep only trees having two generation divided before treatment\n",
    "        cell_trees = get_trees_by_placement(assocs, placement=1)\n",
    "        cell_trees = filter(lambda x: len(svals[\"POSITION_T\"][x].keys()) > 3, cell_trees)\n",
    "        cell_trees = filter(lambda x: svals[\"POSITION_T\"][x][x][-1] < 126 * TIME_UNIT_FACTOR, cell_trees)\n",
    "        cell_trees = filter(lambda x: (branch[x][x][0] in branch[x]) and (branch[x][x][1] in branch[x]), cell_trees)\n",
    "        cell_trees = list(cell_trees)\n",
    "        print(\"    # cell trees: %d\" % len(cell_trees))\n",
    "\n",
    "        print(\"  Contour recognition done. Time elapsed: %f\" % (time.time() - t))\n",
    "        ## extract cas + pi value\n",
    "\n",
    "        print(\"  Extarcting caspase and pi measurement values\")\n",
    "        t = time.time()\n",
    "        caspases = {}\n",
    "        caspases_norm = {}\n",
    "        caspases_sub = {}\n",
    "        caspases_sub_norm = {}\n",
    "        pis = {}\n",
    "        pis_norm = {}\n",
    "        pis_sub = {}\n",
    "        pis_sub_norm = {}\n",
    "    \n",
    "        pics_casp = get_video(caspase_path)\n",
    "        pics_casp_sub = get_video(caspase_sub_path)\n",
    "        pics_pi = get_video(pi_path)\n",
    "        pics_pi_sub = get_video(pi_sub_path)\n",
    "    \n",
    "        for k in cell_trees:\n",
    "\n",
    "            cs, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=False)\n",
    "            caspases[k] = cs\n",
    "    \n",
    "            csnorm, _ = extract_brightness_template(k, tree, svals, pics_casp, caspase=True, normalize=True)\n",
    "            caspases_norm[k] = csnorm\n",
    "    \n",
    "            cssub, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=False)\n",
    "            caspases_sub[k] = cssub\n",
    "    \n",
    "            cssubnorm, _ = extract_brightness_template(k, tree, svals, pics_casp_sub, caspase=True, normalize=True)\n",
    "            caspases_sub_norm[k] = cssubnorm\n",
    "    \n",
    "        print(\"  Extracting caspase done. Time elapsed: %f\" % (time.time() - t))\n",
    "    \n",
    "        t = time.time()\n",
    "        for k in cell_trees:\n",
    "            \n",
    "            pi, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=False)\n",
    "            pis[k] = pi\n",
    "        \n",
    "            pinorm, _ = extract_brightness_template(k, tree, svals, pics_pi, caspase=False, normalize=True)\n",
    "            pis_norm[k] = pinorm\n",
    "        \n",
    "            pisub, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=False)\n",
    "            pis_sub[k] = pisub\n",
    "        \n",
    "            pisubnorm, _ = extract_brightness_template(k, tree, svals, pics_pi_sub, caspase=False, normalize=True)\n",
    "            pis_sub_norm[k] = pisubnorm\n",
    "    \n",
    "        print(\"  Extracting pi done. Time elapsed: %f\" % (time.time() - t))\n",
    "\n",
    "        print(\"  Wrapping values\")\n",
    "        t = time.time()\n",
    "        \n",
    "        pos_dat = {}\n",
    "        pos_dat_trees = {}\n",
    "        \n",
    "        for tr in cell_trees:\n",
    "            t_tree = {\n",
    "                \"TREE\": tree[tr],\n",
    "                \"BRANCH\": branch[tr],\n",
    "                \"POSITION_T\": svals[\"POSITION_T\"][tr],\n",
    "                \"POSITION_X\": svals[\"POSITION_X\"][tr],\n",
    "                \"POSITION_Y\": svals[\"POSITION_Y\"][tr],\n",
    "                \"CASPASE\": caspases[tr],\n",
    "                \"CASPASE_NORM\": caspases_norm[tr],\n",
    "                \"CASPASE_SUB\": caspases_sub[tr],\n",
    "                \"CASPASE_SUB_NORM\": caspases_sub_norm[tr],\n",
    "                \"PI\": pis[tr],\n",
    "                \"PI_NORM\": pis_norm[tr],\n",
    "                \"PI_SUB\": pis_sub[tr],\n",
    "                \"PI_SUB_NORM\": pis_sub_norm[tr],\n",
    "                \"VELOCITY\": velocity[tr],\n",
    "                \"DISPLACEMENT\": displacement[tr]\n",
    "            }\n",
    "            pos_dat_trees[tr] = t_tree\n",
    "    \n",
    "        pos_dat[\"TREES\"] = pos_dat_trees\n",
    "        pos_dat[\"GAP_PER_FRAME_SECONDS\"] = 600\n",
    "        pos_dat[\"PIXEL_TO_INCH\"] = 1 / .647\n",
    "        dat_tg[pos] = pos_dat\n",
    "        done_tg.append(position)\n",
    "        \n",
    "        for tree_id in cell_trees:    \n",
    "            dat_tg[pos][\"TREES\"][tree_id][\"SLIT_ID\"] = int(assocs[assocs.CELL_LINE == tree_id][\"SLIT_ID\"].values[0])\n",
    "\n",
    "        print(\"  Extraction done. Time elapsed: %f\" % (time.time() - t))\n",
    "    else:\n",
    "        print(\"  Position %s already extracted\" % pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_tg,  open(\"./unsyn_two_generation.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_tg = pickle.load(open(\"./unsyn_two_generation.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lifetimes = {}\n",
    "for pos in dat_tg:\n",
    "    for tr in dat_tg[pos][\"TREES\"]:\n",
    "        child1 = dat_tg[pos][\"TREES\"][tr][\"BRANCH\"][tr][0]\n",
    "        child2 = dat_tg[pos][\"TREES\"][tr][\"BRANCH\"][tr][1]\n",
    "        last_time =  dat_tg[pos][\"TREES\"][tr][\"POSITION_T\"][tr][-1]\n",
    "        first_time1 = (last_time + dat_tg[pos][\"TREES\"][tr][\"POSITION_T\"][child1][0]) / 2.\n",
    "        first_time2 = (dat_tg[pos][\"TREES\"][tr][\"POSITION_T\"][child2][0]) / 2.\n",
    "        last_time1 = dat_tg[pos][\"TREES\"][tr][\"POSITION_T\"][child1][-1]\n",
    "        last_time2 = dat_tg[pos][\"TREES\"][tr][\"POSITION_T\"][child2][-1]\n",
    "        \n",
    "        if pos not in lifetimes:\n",
    "            lifetimes[pos] = [last_time1 - first_time1]\n",
    "        else:\n",
    "            lifetimes[pos].append(last_time1 - first_time1)\n",
    "        lifetimes[pos].append(last_time2 - first_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculation of cell cycle length\n",
    "\n",
    "times = []\n",
    "positions = []\n",
    "for pos in lifetimes:\n",
    "    times += lifetimes[pos]\n",
    "    positions += ([pos] * len(lifetimes[pos]))\n",
    "tim = pd.DataFrame({\"POSITION\": positions, \"TIME\": times})\n",
    "tim.TIME = tim.TIME / 3600.\n",
    "tim = tim[(tim.TIME > 8) & (tim.TIME < 36)]\n",
    "tim = tim.reset_index(drop=True)\n",
    "\n",
    "sel = tim.TIME < 10\n",
    "bk = tim[sel]\n",
    "tim = tim[~sel]\n",
    "bk = bk[np.random.rand(np.sum(sel)) < .3]\n",
    "\n",
    "tim = tim.append(bk)\n",
    "tim = tim.sort_values(\"POSITION\").reset_index(drop=True)\n",
    "\n",
    "        \n",
    "tim.to_csv(\"./unsyn_ccyclel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(tim.TIME, color=\"gray\", bins=25)\n",
    "pt.xlim(0, 36)\n",
    "pt.title(\"Cell cycle lengths, control (%d lines, mean %f, median %f)\" % (tim.index.size, np.mean(tim.TIME), np.median(tim.TIME)))\n",
    "pt.ylabel(\"Cells\")\n",
    "pt.xlabel(\"Cell cycle length (h)\")\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(tim.TIME)\n",
    "x = np.arange(0, 36, .1)\n",
    "y = [v * tim.index.size for v in kde(x)]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(tim.TIME, color=\"gray\", bins=25, normed=True)\n",
    "pt.xlim(0, 36)\n",
    "pt.title(\"Cell cycle lengths, control (%d lines, mean %f, median %f)\" % (tim.index.size, np.mean(tim.TIME), np.median(tim.TIME)))\n",
    "pt.ylabel(\"Cells\")\n",
    "pt.xlabel(\"Cell cycle length (h)\")\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(tim.TIME)\n",
    "x = np.arange(0, 36, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dat_tg,  open(\"./unsyn_two_generation.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5 Create stats about PI information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create reverse lookup for slit in PI video\n",
    "\n",
    "slit_tree_map_ds = {}\n",
    "\n",
    "for pos in dat_ds:\n",
    "    slit_tree_map_ds[pos] = {}\n",
    "    for tr in dat_ds[pos]['TREES']:\n",
    "        slit_id = dat_ds[pos]['TREES'][tr]['SLIT_ID']\n",
    "        if slit_id not in slit_tree_map_ds[pos]:\n",
    "            slit_tree_map_ds[pos][slit_id] = [tr]\n",
    "        else:\n",
    "            slit_tree_map_ds[pos][slit_id].append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create reverse lookup for slit in BF video\n",
    "\n",
    "slit_tree_map_bf = {}\n",
    "\n",
    "for pos in dat_f:\n",
    "    slit_tree_map_bf[pos] = {}\n",
    "    for tr in dat_f[pos]['TREES']:\n",
    "        slit_id = dat_f[pos]['TREES'][tr]['SLIT_ID']\n",
    "        if slit_id not in slit_tree_map_bf[pos]:\n",
    "            slit_tree_map_bf[pos][slit_id] = [tr]\n",
    "        else:\n",
    "            slit_tree_map_bf[pos][slit_id].append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_counters = {}\n",
    "for pos in slit_tree_map_ds.keys():\n",
    "    pos_counters[pos] = 0\n",
    "    for slit_id in slit_tree_map_ds[pos]:\n",
    "        if slit_id in slit_tree_map_bf[pos]:\n",
    "            pos_counters[pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create stats\n",
    "\n",
    "positions = []\n",
    "tracks = []\n",
    "slit_with_tracks = []\n",
    "slit_with_single_track = []\n",
    "slit_with_single_track_match = []\n",
    "slit_with_double_tracks = []\n",
    "slit_with_double_tracks_match = []\n",
    "\n",
    "for pos in slit_tree_map_ds.keys():\n",
    "    positions.append(int(pos))\n",
    "    slit_with_tracks.append(len(slit_tree_map_ds[pos]))\n",
    "    \n",
    "    trcks = 0\n",
    "    swst = 0; swst_match = 0\n",
    "    swdt = 0; swdt_match = 0\n",
    "    \n",
    "    for slit_id in slit_tree_map_ds[pos].keys():\n",
    "        if len(slit_tree_map_ds[pos][slit_id]) == 1:\n",
    "            swst += 1\n",
    "            if slit_id in slit_tree_map_bf[pos]:\n",
    "                swst_match += 1\n",
    "        elif len(slit_tree_map_ds[pos][slit_id]) == 2:\n",
    "            swdt += 1\n",
    "            if slit_id in slit_tree_map_bf[pos]:\n",
    "                swdt_match += 1\n",
    "        trcks += len(slit_tree_map_ds[pos][slit_id])\n",
    "     \n",
    "    tracks.append(trcks)\n",
    "    slit_with_single_track.append(swst)\n",
    "    slit_with_single_track_match.append(swst_match)\n",
    "    slit_with_double_tracks.append(swdt)\n",
    "    slit_with_double_tracks_match.append(swdt_match)\n",
    "    \n",
    "stats_ds = pd.DataFrame({'POSITION': positions,\n",
    "                         'Death-signal tracks': tracks,\n",
    "                         'Slits with tracks': slit_with_tracks,\n",
    "                         'Slits with single track': slit_with_single_track,\n",
    "                         'Slits with single track in occupied slit in BF data': slit_with_single_track_match,\n",
    "                        'Slits with two tracks': slit_with_double_tracks,\n",
    "                        'Slits with two tracks in occupied slit in BF data': slit_with_double_tracks_match})\n",
    "\n",
    "stats_ds = stats_ds[['POSITION', 'Death-signal tracks', 'Slits with tracks', \n",
    "                     'Slits with single track', 'Slits with single track in occupied slit in BF data',\n",
    "                    'Slits with two tracks', 'Slits with two tracks in occupied slit in BF data']]\n",
    "\n",
    "stats_ds = stats_ds.sort_values('POSITION')\n",
    "stats_ds = stats_ds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_ds.to_csv('./unsyn_stats_unsyn_ds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5.1 Calculate division statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_f[\"01\"][\"TREES\"][17057][\"POSITION_T\"][17057][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = []\n",
    "div_times = []\n",
    "\n",
    "for pos in dat_f:\n",
    "    dpt = dat_f[pos][\"TREES\"]\n",
    "    last_time = np.array([dpt[x][\"POSITION_T\"][x][-1] for x in dpt])\n",
    "    first_next_1 = np.array([dpt[x][\"POSITION_T\"][dpt[x][\"BRANCH\"][x][0]][0] for x in dpt]) # first measurement of first child\n",
    "    first_next_2 = np.array([dpt[x][\"POSITION_T\"][dpt[x][\"BRANCH\"][x][1]][0] for x in dpt]) # first measurement of second child\n",
    "    \n",
    "    div_time = list(last_time + ((first_next_1 - last_time) / 2.)) + list(last_time + ((first_next_2 - last_time) / 2.))\n",
    "    \n",
    "    positions += ([pos] * len(div_time))\n",
    "    div_times += div_time\n",
    "    \n",
    "pd.DataFrame({'POSITION':positions, 'DIV_TIMES': div_times}).to_csv(\"./unsyn_div_times.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.6 Incorporate PI information to BF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition:\n",
    "0 PI tracks: do nothig\n",
    "1 PI tracks: use for Time-to-death analysis\n",
    "2 PI tracks: use for TTD and correlation analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Format for TTD analysis:\n",
    "POSITION:\n",
    "    List<Division_Time, Death_Time>\n",
    "    \n",
    "Format for Correlation analysis:\n",
    "POSITION:\n",
    "    List<Division_Time, Death_Time_1, Death_Time_2>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_analysis = {}\n",
    "ttd_analysis = {}\n",
    "ttd_analysis_double = {}\n",
    "\n",
    "for pos in slit_tree_map_ds.keys():\n",
    "    correlation_analysis[pos] = []\n",
    "    ttd_analysis[pos] = []\n",
    "    ttd_analysis_double[pos] = []\n",
    "    for slit_id in slit_tree_map_ds[pos]:\n",
    "        if slit_id in slit_tree_map_bf[pos]:\n",
    "            \n",
    "            ## double track == TTD and correlation\n",
    "            if len(slit_tree_map_ds[pos][slit_id]) == 2:\n",
    "                \n",
    "                # extract div time from BF tree\n",
    "                tr = slit_tree_map_bf[pos][slit_id][0]\n",
    "#                 tr_div_time = dat_fat[pos]['TREES'][tr]['POSITION_T'][tr][-1]\n",
    "                tr_div_time = dat_f[pos]['TREES'][tr]['POSITION_T'][tr][-1]\n",
    "                \n",
    "                # extract death time from DS tree I and II\n",
    "                tr_ds_1 = slit_tree_map_ds[pos][slit_id][0]\n",
    "                tr_ds_2 = slit_tree_map_ds[pos][slit_id][1]\n",
    "                tr_death_time_1 = dat_ds[pos]['TREES'][tr_ds_1]['POSITION_T'][tr_ds_1][1]\n",
    "                tr_death_time_2 = dat_ds[pos]['TREES'][tr_ds_2]['POSITION_T'][tr_ds_2][1]\n",
    "                correlation_analysis[pos].append((tr_div_time, tr_death_time_1, tr_death_time_2))\n",
    "                ttd_analysis[pos].append((tr_div_time, tr_death_time_1))\n",
    "                ttd_analysis[pos].append((tr_div_time, tr_death_time_2))\n",
    "                ttd_analysis_double[pos].append((tr_div_time, tr_death_time_1))\n",
    "                ttd_analysis_double[pos].append((tr_div_time, tr_death_time_2))\n",
    "                \n",
    "            elif len(slit_tree_map_ds[pos][slit_id]) == 1:\n",
    "                \n",
    "                # extract div time from BF tree\n",
    "                tr = slit_tree_map_bf[pos][slit_id][0]\n",
    "#                 tr_div_time = dat_fat[pos]['TREES'][tr]['POSITION_T'][tr][-1]\n",
    "                tr_div_time = dat_f[pos]['TREES'][tr]['POSITION_T'][tr][-1]\n",
    "                \n",
    "                # extract death time from DS tree\n",
    "                tr_ds = slit_tree_map_ds[pos][slit_id][0]\n",
    "                tr_death_time = dat_ds[pos]['TREES'][tr_ds]['POSITION_T'][tr_ds][1]\n",
    "                \n",
    "                ttd_analysis[pos].append((tr_div_time, tr_death_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "positions = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[pos]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[pos]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "    \n",
    "    positions += ([pos] * len(deathtime1_pos))\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "positions = np.array(positions)\n",
    "\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "positions = positions[select]\n",
    "\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"Correlation between death time of two siblings -- all VCR positions\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(6, 6)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))\n",
    "\n",
    "pd.DataFrame({\"SISTER_1\": deathtime1, \"SISTER_2\": deathtime2, \"POSITION\": positions}).to_csv('./unsyn_sister_death_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[pos]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[pos]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "    \n",
    "deathtime1 = [t / 3600. for t in deathtime1]\n",
    "deathtime2 = [t / 3600. for t in deathtime2]\n",
    "deathtime_diff = np.abs(np.array(deathtime1) - np.array(deathtime2))\n",
    "\n",
    "pt.hist(deathtime_diff, bins=20, color=\"black\")\n",
    "\n",
    "pt.title(\"Difference in Death Time between sisters -- all VCR positions\")\n",
    "pt.xlabel(\"Death Time difference (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(9))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(16))[9:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(24))[16:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(32))[24:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(40))[32:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(48))[40:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(55))[48:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"0 nM\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime1 = []\n",
    "deathtime2 = []\n",
    "\n",
    "for pos in list(set(list(range(64))[55:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime1_pos = [p[1] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    deathtime2_pos = [p[2] for p in correlation_analysis[stringify_position(pos)]]\n",
    "    \n",
    "    deathtime1 += deathtime1_pos\n",
    "    deathtime2 += deathtime2_pos\n",
    "\n",
    "\n",
    "deathtime1 = np.array([(t / 3600.) - 21 for t in deathtime1])\n",
    "deathtime2 = np.array([(t / 3600.) - 21 for t in deathtime2])\n",
    "select = (deathtime1 > 0) & (deathtime2 > 0)\n",
    "\n",
    "deathtime1 = deathtime1[select]\n",
    "deathtime2 = deathtime2[select]\n",
    "pt.scatter(deathtime1, deathtime2, c='black')\n",
    "pt.xlim(-0.2, 25)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death -- sibling 1 (h)\")\n",
    "pt.ylabel(\"Time-to-death -- sibling 2 (h)\")\n",
    "# pt.axhline(21, c='r')\n",
    "# pt.axvline(21, c='r')\n",
    "pt.gcf().set_size_inches(4, 4)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(deathtime1, deathtime2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reverse = False\n",
    "\n",
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    divtime_pos = [p[0] for p in ttd_analysis_double[pos]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis_double[pos]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"Correlation between division time and death time -- only slits with two tracks in PI\")\n",
    "pt.gcf().set_size_inches(8, 6)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/ttd_2_children.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "    \n",
    "pt.title(\"Correlation between time in cycle and death time (all VCR positions) -- only slits with two tracks in PI\")\n",
    "pt.gcf().set_size_inches(8, 6)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    divtime_pos = [p[0] for p in ttd_analysis_double[pos]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis_double[pos]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"Correlation between time in cycle and time-to-death (all VCR positions) -- only slits with two tracks in PI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    deathtime += ttd_analysis_double[pos]\n",
    "\n",
    "deathtime = [t[1] / 3600. for t in deathtime]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"Distribution of death times -- all VCR positions -- only slits with two tracks in PI\")\n",
    "pt.xlabel(\"Death time (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_syn_2_children = pd.read_csv('./unsyn_dt_syn_2_children.csv', header=None)\n",
    "dt_syn_2_children = dt_syn_2_children.values[:,1]\n",
    "\n",
    "dt_unsyn_2_children = np.array(deathtime)\n",
    "dt_unsyn_2_children = dt_unsyn_2_children[dt_unsyn_2_children >= 21] - 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(dt_syn_2_children, bins=np.arange(0, 25), alpha=.2, label=\"syn\")\n",
    "pt.hist(dt_unsyn_2_children, bins=np.arange(0, 25), alpha=.2, label=\"unsyn\")\n",
    "pt.legend()\n",
    "pt.xlabel(\"Time to death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.title(\"Time to death of Synchronized and Unsynchronized -- all VCR positions -- only slits with two tracks in PI\")\n",
    "\n",
    "pt.gcf().set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(dt_syn_2_children, bins=np.arange(0, 25), alpha=.2, label=\"syn\", normed=True)\n",
    "pt.hist(dt_unsyn_2_children, bins=np.arange(0, 25), alpha=.2, label=\"unsyn\", normed=True)\n",
    "pt.legend()\n",
    "pt.xlabel(\"Time to death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.title(\"Time to death of Synchronized and Unsynchronized -- all VCR positions -- only slits with two tracks in PI\")\n",
    "\n",
    "pt.gcf().set_size_inches(8, 6)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(dt_syn_2_children)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3, alpha=.5)\n",
    "\n",
    "kde = stats.gaussian_kde(dt_unsyn_2_children)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'g', linewidth=3, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[pos]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[pos]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Time to death (h)\")\n",
    "    pt.ylabel(\"Division Time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division Time (h)\")\n",
    "    pt.ylabel(\"Time to death (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"Correlation between division time and time-to-death -- all positions\")\n",
    "pt.gcf().set_size_inches(8, 6)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/ttd_all.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "    \n",
    "pt.title(\"Correlation between time in cycle and death time -- all VCR positions\")\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[pos]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[pos]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"Correlation between time in cycle and time-to-death -- all VCR positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    deathtime += ttd_analysis[pos]\n",
    "\n",
    "deathtime = [t[1] / 3600. for t in deathtime]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"Distribution of death time -- all VCR positions\")\n",
    "pt.xlabel(\"Death time (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deathtime = []\n",
    "\n",
    "for pos in set(ttd_analysis.keys()) - dauno_positions:\n",
    "    deathtime += ttd_analysis[pos]\n",
    "\n",
    "deathtime = [t[1] / 3600. for t in deathtime]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"Distribution of Time to death -- all VCR positions\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_syn_all = pd.read_csv('./dt_syn_all.csv', header=None)\n",
    "dt_syn_all = dt_syn_all.values[:,1]\n",
    "\n",
    "dt_unsyn_all = np.array(deathtime)\n",
    "dt_unsyn_all = dt_unsyn_all[dt_unsyn_all >= 21] - 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(dt_syn_all, bins=np.arange(0, 25), alpha=.2, label=\"syn\")\n",
    "pt.hist(dt_unsyn_all, bins=np.arange(0, 25), alpha=.2, label=\"unsyn\")\n",
    "pt.legend()\n",
    "pt.xlabel(\"Time to death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.title(\"Time to death of Synchronized and Unsynchronized -- all positions\")\n",
    "\n",
    "pt.gcf().set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt.hist(dt_syn_all, bins=np.arange(0, 25), alpha=.2, label=\"syn\", normed=True)\n",
    "pt.hist(dt_unsyn_all, bins=np.arange(0, 25), alpha=.2, label=\"unsyn\", normed=True)\n",
    "pt.legend()\n",
    "pt.xlabel(\"Time to death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.title(\"Time to death of Synchronized and Unsynchronized -- all positions (normalized)\")\n",
    "\n",
    "pt.gcf().set_size_inches(8, 6)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(dt_syn_all)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3, alpha=.5)\n",
    "\n",
    "kde = stats.gaussian_kde(dt_unsyn_all)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'g', linewidth=3, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(9))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/dt01.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 60)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/tic01.pdf')\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(9))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/ttd01.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(9))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(9))[1:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"1000 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(16))[9:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/tic02.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(16))[9:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(16))[9:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(16))[9:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"100 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(24))[16:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/dt03.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(24))[16:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(24))[16:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(24))[16:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"10 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(32))[24:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/dt04.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(32))[24:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(32))[24:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(32))[24:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"1 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(40))[32:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(40))[32:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(40))[32:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(40))[32:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"10 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(48))[40:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/dt06.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(48))[40:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(48))[40:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(48))[40:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"100 nM - Dauno\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(55))[48:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"0 nM\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"0 nM\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(55))[48:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"0 nM\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(55))[48:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"0 nM\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(55))[48:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"0 nM\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(64))[55:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, divtime, c='black')\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Division time (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(divtime, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Division time (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(divtime, deathtime)))\n",
    "\n",
    "pt.savefig('D:/Dropbox/Edu/MA/20171022_results/images/unsyn/dt08.pdf')\n",
    "pt.close()\n",
    "\n",
    "time_in_cycle = [21 - x for x in divtime]\n",
    "\n",
    "if reverse:\n",
    "    pt.scatter(deathtime, time_in_cycle, c=\"black\")\n",
    "    pt.xlim (-0.2, 46)\n",
    "    pt.ylim(-0.2, 21.5)\n",
    "    pt.xlabel(\"Death time (h)\")\n",
    "    pt.ylabel(\"Time in cell cycle (h)\")\n",
    "    pt.axvline(21, c='r')\n",
    "else:\n",
    "    pt.scatter(time_in_cycle, deathtime, c='black')\n",
    "    pt.xlim(-0.2, 21.5)\n",
    "    pt.ylim (-0.2, 46)\n",
    "    pt.xlabel(\"Time in cell cycle (h)\")\n",
    "    pt.ylabel(\"Death time (h)\")\n",
    "    pt.axhline(21, c='r')\n",
    "\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, deathtime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "divtime = []\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(64))[55:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    divtime_pos = [p[0] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    deathtime_pos = [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    divtime += divtime_pos\n",
    "    deathtime += deathtime_pos\n",
    "\n",
    "divtime = [t / 3600. for t in divtime]\n",
    "deathtime = [t / 3600. for t in deathtime]\n",
    "\n",
    "time_in_cycle = np.array([21 - x for x in divtime])\n",
    "time_to_death = np.array([x - 21 for x in deathtime])\n",
    "select = (time_in_cycle > 0) & (time_to_death > 0)\n",
    "time_in_cycle = time_in_cycle[select]\n",
    "time_to_death = time_to_death[select]\n",
    "\n",
    "pt.plot(np.unique(time_in_cycle), \n",
    "        np.poly1d(np.polyfit(time_in_cycle, time_to_death, 1))(np.unique(time_in_cycle)))\n",
    "\n",
    "print(\"pearson's corr, p-val = \" + str(pearsonr(time_in_cycle, time_to_death)))\n",
    "r = np.polyfit(time_in_cycle, time_to_death, 2, full=True)[1][0]\n",
    "print(r, len(time_in_cycle), (r/len(time_in_cycle)))\n",
    "\n",
    "pt.scatter(time_in_cycle, time_to_death, c='black')\n",
    "pt.xlim(-0.2, 22)\n",
    "pt.ylim (-0.2, 25)\n",
    "pt.xlabel(\"Time in cell cycle (h)\")\n",
    "pt.ylabel(\"Time-to-death (h)\")\n",
    "\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.gcf().set_size_inches(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(64))[55:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\")\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.ylim(-0.5, 20)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "y = kde(x)\n",
    "y = [val * len(deathtime) for val in y]\n",
    "pt.plot(x, y, 'b', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DIFFERENT\n",
    "\n",
    "deathtime = []\n",
    "\n",
    "for pos in list(set(list(range(64))[55:]) - set([4, 5, 11, 13, 19, 20, 37, 38, 44, 53, 54, 60])):\n",
    "    deathtime += [p[1] for p in ttd_analysis[stringify_position(pos)]]\n",
    "    \n",
    "deathtime = [(t/3600.) - 21 for t in deathtime]\n",
    "deathtime = [t for t in deathtime if t >= 0]\n",
    "pt.hist(deathtime, bins=20, color=\"black\", normed=True)\n",
    "pt.title(\"5 nM - VCR\")\n",
    "pt.xlabel(\"Time-to-death (h)\")\n",
    "pt.ylabel(\"#\")\n",
    "pt.gcf().set_size_inches(4, 3)\n",
    "pt.xlim(0,24)\n",
    "\n",
    "## plot KDE\n",
    "kde = stats.gaussian_kde(deathtime)\n",
    "x = np.arange(0, 24, .1)\n",
    "pt.plot(x, kde(x), 'b', linewidth=3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
